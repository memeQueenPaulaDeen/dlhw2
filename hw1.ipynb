{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Math, Latex\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>HomeWork #2</h1>\n",
    "<h2>Sami Wood</h2>\n",
    "\n",
    "<h3>Problem 1</h3>\n",
    "\n",
    "\n",
    "\n",
    "<h4>Part A:</h4>\n",
    "Build a Naïve Bayes classifierusing the data shown in Table 1to predict whether a text filewill be saved (class label y = +1) or discarded(y = -1). The features (x(i), i = 1, 2, ..., 5) are binary values (representing some attributes of a text file, e.g., “known author or not”, “long or short”, etc.).\n",
    "\n",
    "\n",
    "The classifier computes the probability in the following steps:\n",
    "\n",
    "<li>Step 1: Compute the prior probability for each class(p(y)), y+-1 or +1;</li>\n",
    "<li>Step 2: Computethe likelihood probability with each classfor each feature (p(x(i)| y))</li>\n",
    "<li>Step 3: Calculate the posterior probability for each class given each feature (p(y | x(i));</li>\n",
    "<li>Step 4: Predictaclass for a given text filebased on the posterior probability. Specifically, what is the posterior probability that y = +1 given the feature vectorx = (1 1 0 1 0). Which class would be predicted for x = (0 0 0 0 0)? What about for x = (1 1 0 1 0)</li>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x1':[0,1,0,1,0,1,0,1,1,1],\n",
    "                   'x2':[0,1,1,1,1,0,0,0,0,1],\n",
    "                   'x3':[1,0,1,1,0,1,1,0,1,1],\n",
    "                   'x4':[1,1,1,1,0,1,0,0,1,1],\n",
    "                   'x5':[0,0,1,0,0,1,0,0,0,1],\n",
    "                   'y' :[-1,-1,-1,-1,-1,1,1,1,1,-1]})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Step 1</b>\n",
    "calculate prior for each class:\n",
    "\n",
    "In this case we have only two classes and we can simply look at the relative frequencies of each class.\n",
    "We would do this with the following equation:\n",
    "\n",
    "$$\\frac{NumInClass}{Total}$$\n",
    "\n",
    "The calculation is shown below"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for class 1: 0.4\n",
      "prior for class -1: 0.6\n"
     ]
    }
   ],
   "source": [
    "p1 = len(df.loc[df['y'] == 1])/len(df)\n",
    "pm1 = len(df.loc[df['y'] == -1])/len(df)\n",
    "print('prior for class 1: ' + str(p1))\n",
    "print('prior for class -1: ' + str(pm1))\n",
    "priorDf = pd.DataFrame({'y':[1,-1],'prob':[p1,pm1]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Step 2:</b>\n",
    "In order to find the probability of a class given some input we can apply bayes rule:\n",
    "\n",
    "$$P(y_i|x_1,x_2...,x_n) = P(x_1,x_2,...,x_n) * P(y_i)$$\n",
    "\n",
    "This calculation can be greatly simplified if we make the assumption that all the input variables x are independent.\n",
    "\n",
    "$$P(y_i|x_1,x_2,...,x_n) = P(x_1|y_i)*P(x_2|y_i)*...*P(x_n|y_i)*P(y_i)$$\n",
    "\n",
    "Now we can work with this equation as we can calculate the individual probability distribution terms as follows:\n",
    "\n",
    "$$P(x_j|y_i) = count(x_i)/count(y)$$\n",
    "\n",
    "when done for each variable $x_j$ with $y_i$ we will have a binary probability distribution for each variable $x_j$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x1        x2        x3        x4        x5  y\n",
      "x1                                                 \n",
      "0   0.25  1.000000  0.250000  0.500000  0.750000  1\n",
      "1   0.75  0.000000  0.750000  0.500000  0.250000  1\n",
      "0   0.50  0.166667  0.333333  0.166667  0.666667 -1\n",
      "1   0.50  0.833333  0.666667  0.833333  0.333333 -1\n"
     ]
    }
   ],
   "source": [
    "pdf = pd.DataFrame([])\n",
    "for y in set(df.y):\n",
    "    mini = df.loc[df.y == y]\n",
    "    pdfmini = pd.DataFrame([])\n",
    "    u = len(mini)\n",
    "    for x in df.columns:\n",
    "        if x != 'y':\n",
    "            pdfmini[x]  = mini.groupby(x).size()/u\n",
    "    pdfmini['y'] = y\n",
    "    pdf = pdf.append(pdfmini)\n",
    "\n",
    "pdf.fillna(0,inplace=True)\n",
    "print(pdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Step 3:</b>\n",
    "Now that we have a probability distribution of our inputs given the observation of our outputs we can apply bayes rule to find a probability distrobution of outputs given inputs.\n",
    "Again this is simply calculated assuming the inputs are independent as follows:\n",
    "\n",
    "$$P(y_i|x_1,x_2,...,x_n) = P(x_1|y_i)*P(x_2|y_i)*...*P(x_n|y_i)*P(y_i)$$\n",
    "\n",
    "For the given data we can calculate a probability distribution for each row.\n",
    "We can use this as a sanity check.\n",
    "One would hope to see for the most part the class with the\n",
    "highest probability would correspond to the actual class of the row. Another check is that probabilites should sum to 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  0   0   1   1   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.070312\n",
      "-1 0.030864\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   1   0   1   0\n",
      "the probability distribution is: \n",
      " y      py\n",
      " 1 0.00000\n",
      "-1 0.07716\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  0   1   1   1   1\n",
      "the probability distribution is: \n",
      " y      py\n",
      " 1 0.00000\n",
      "-1 0.07716\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   1   1   1   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.000000\n",
      "-1 0.154321\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  0   1   0   0   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.000000\n",
      "-1 0.015432\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   0   1   1   1\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.070312\n",
      "-1 0.015432\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  0   0   1   0   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.070312\n",
      "-1 0.006173\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   0   0   0   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.070312\n",
      "-1 0.003086\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   0   1   1   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.210938\n",
      "-1 0.030864\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   1   1   1   1\n",
      "the probability distribution is: \n",
      " y      py\n",
      " 1 0.00000\n",
      "-1 0.07716\n",
      "\n",
      "\n",
      "sum of all probabilites is: 0.9798418209876545\n"
     ]
    }
   ],
   "source": [
    "summer = []\n",
    "def getProbOfOutput(row):\n",
    "    def inner(priorRow):\n",
    "        pdfgy = pdf.loc[pdf.y == priorRow.y]\n",
    "        prob = 1\n",
    "        colIdx = 0\n",
    "        for input in row:\n",
    "            prob = prob * pdfgy.iloc[input,colIdx]\n",
    "            colIdx = colIdx + 1\n",
    "        summer.append(prob)\n",
    "        return prob\n",
    "\n",
    "    priorDf['py'] = 0\n",
    "    priorDf['py'] = priorDf.apply(lambda rx: inner(rx) ,axis=1)\n",
    "    print('Given')\n",
    "    print(row.to_frame().T.to_string(index=False))\n",
    "    print(\"the probability distribution is: \")\n",
    "    print(priorDf[['y','py']].to_string(index=False))\n",
    "    print('\\n')\n",
    "\n",
    "ignore = df.drop(columns='y').apply(lambda x: getProbOfOutput(x),axis = 1)\n",
    "print('sum of all probabilites is: ' + str(sum(summer)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Step 4:</b> Prediction\n",
    "Finally we may also use our classifier to predict new data.\n",
    "This process is exactly the same as step 3 only now we may be predicting never before seen data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  1   1   0   1   0\n",
      "the probability distribution is: \n",
      " y      py\n",
      " 1 0.00000\n",
      "-1 0.07716\n",
      "\n",
      "\n",
      "Given\n",
      " x1  x2  x3  x4  x5\n",
      "  0   0   0   0   0\n",
      "the probability distribution is: \n",
      " y       py\n",
      " 1 0.023438\n",
      "-1 0.003086\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inDf = pd.DataFrame({\n",
    "                   'x1':[1,0],\n",
    "                   'x2':[1,0],\n",
    "                   'x3':[0,0],\n",
    "                   'x4':[1,0],\n",
    "                   'x5':[0,0]})\n",
    "ignore = inDf.apply(lambda x: getProbOfOutput(x),axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Part B:</h4>\n",
    "\n",
    "<b>Section 1: Algorithm overview </b>\n",
    "\n",
    "Gaussian Naive Bayes is simply an extension of naive Bayes.\n",
    "Naive Bayes uses the relative frequency of inputs to calculate a simple discrete probability distribution.\n",
    "This idea is extended by instead calculating the mean and standard deviation of inputs with each classification.\n",
    "In doing this we can estimate a continuous probability distribution for each class.\n",
    "Recall the formula of a normal distribution is as follows:\n",
    "\n",
    "$$P(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{ \\frac{-1}{2}\\left( \\frac{x-\\mu}{\\sigma} \\right)^2}$$\n",
    "\n",
    "We can use our training data set to estimate the parameters of the distribution as follows:\n",
    "\n",
    "$$\\mu = \\frac{\\sum x}{n}$$\n",
    "\n",
    "where x is the input variable for some class and n is the frequncy of x in the training data.\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{\\sum(x-\\mu)^2}{n}}$$\n",
    "\n",
    "Given these parameters we arrive at an equation that will describe the probability of an event. From this point we follow the same process as we would with a naive bayes classifer.\n",
    "\n",
    "Again in order to find the probability of a class given some input we can apply bayes rule:\n",
    "\n",
    "$$P(y_i|x_1,x_2...,x_n) = P(x_1,x_2,...,x_n) * P(y_i)$$\n",
    "\n",
    "This calculation can be greatly simplified if we make the assumption that all the input variables x are independent.\n",
    "\n",
    "$$P(y_i|x_1,x_2,...,x_n) = P(x_1|y_i)*P(x_2|y_i)*...*P(x_n|y_i)*P(y_i)$$\n",
    "\n",
    "Now we can work with this equation as we can calculate the individual probability distribution terms by plugging in values given some class $y_i$ as follows:\n",
    "\n",
    "let n_i be the number of samples whose class is $y_i$\n",
    "let x_i be any training data with class label y_i such that\n",
    "\n",
    "$$\\mu_i = \\frac{\\sum x}{n_i}$$\n",
    "\n",
    "$$\\sigma_i = \\sqrt{\\frac{\\sum(x_i-\\mu_i)^2}{n_i}}$$\n",
    "\n",
    "\n",
    "$$P(x_i|y_i) = \\frac{1}{\\sigma_i\\sqrt{2\\pi}}e^{ \\frac{-1}{2}\\left( \\frac{x-\\mu_i}{\\sigma_i} \\right)^2}$$\n",
    "\n",
    "Lastly $P(y_i)$ can simply be calculated as the relative frequcy of the class:\n",
    "\n",
    "$$P(y_i) = \\frac{count(y_i)}{count(y)}$$\n",
    "\n",
    "With all the pieces of the puzzle together we would be able to apply the following formula to find the class probabilities\n",
    "\n",
    "$$P(y_i|x_1,x_2...,x_n) = P(x_1,x_2,...,x_n) * P(y_i)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Section 2: Implantation overview </b>\n",
    "\n",
    "In the following section a Niave Gaussian Bayes code implementation will be used to classify breast cancer samples into malignant or begnin.\n",
    "There are 30 features which are used to inform the classification.\n",
    "More information on the dataset may be found at the following:\n",
    "<href>https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html</href>\n",
    "\n",
    "<b>Section 2 a: Implantation</b>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data,data.target,test_size=.2)\n",
    "ngclf = GaussianNB()\n",
    "ngclf.fit(X_train,y_train)\n",
    "print('mean accuracy of the classifier is: ' + str(ngclf.score(X_test,y_test)))\n",
    "print('The confusion matrix is: ' + str(confusion_matrix(y_test, ngclf.predict(X_test))))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}